{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b90e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f040f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import tentaclio\n",
    "# import hulearn\n",
    "import sklearn\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from phoenix.common import artifacts\n",
    "from phoenix.common import utils\n",
    "from phoenix.custom_models.tension_classifier import process_annotations\n",
    "from phoenix.custom_models.tension_classifier.tension_classifier import CountVectorizerTensionClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b89e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametrise the run execution date.\n",
    "# Format of the run date\n",
    "RUN_DATE_FORMAT = \"%Y-%m-%d\"\n",
    "# This can be overwritten at execution time by Papermill to enable historic runs and backfills etc.\n",
    "RUN_DATE = datetime.datetime.today().strftime(RUN_DATE_FORMAT)\n",
    "\n",
    "# Set Artefacts URL\n",
    "ARTIFACTS_BASE_URL = f\"{artifacts.urls.get_local()}{RUN_DATE}/\"\n",
    "\n",
    "# Input\n",
    "FOLDER_ANNOTATIONS = f\"{artifacts.urls.get_local()}input_csvs/annotated_data/\"\n",
    "\n",
    "## Crude cutoff point where any row above this int becomes the validation set\n",
    "MAX_TRAIN_TEST_ROW = 1797\n",
    "MAX_ANNOTATION_ROW = 2000\n",
    "## Only try to classify a tension if there are at least this many objects\n",
    "MIN_NUM_OBJECTS_PER_TENSION = 60\n",
    "\n",
    "# Output just uses ARTIFACTS_BASE_URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3095a6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.setup_notebook_output()\n",
    "utils.setup_notebook_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae6a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display params.\n",
    "print(\n",
    "ARTIFACTS_BASE_URL,\n",
    "FOLDER_ANNOTATIONS,\n",
    "MAX_TRAIN_TEST_ROW,\n",
    "MAX_ANNOTATION_ROW,\n",
    "RUN_DATE,\n",
    "sep='\\n',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc7556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_fb_df = pd.read_csv(f\"{FOLDER_ANNOTATIONS}fb_posts_annotated.csv\", header=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ce78b0",
   "metadata": {},
   "source": [
    "### Process annotations for the full dataset to get a complete as possible count_vectorizer.\n",
    "We don't use the topic_df_full for any modeling to prevent leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc9800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full, topic_df_full = process_annotations.process_annotations(annotated_fb_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651b9b8",
   "metadata": {},
   "source": [
    "## The sample is cut off at a max train_test row to create a validation set \n",
    "The validation set has MAX_ANNOTATION_ROW - MAX_TRAIN_TEST_ROW samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6cd443",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = annotated_fb_df.iloc[:MAX_TRAIN_TEST_ROW].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf60692",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, topic_df = process_annotations.process_annotations(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef19a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_annotations.binarise_tensions_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75cc2a7",
   "metadata": {},
   "source": [
    "### Get tension_feature_mapping and topic_df will be used for the next iteration\n",
    "which uses human-learn to try to get human-made functions into a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af3d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensions_dict = process_annotations.get_tension_feature_mapping(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82808cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2532e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eac4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"topics\"] = df_sample[\"topics\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87ccc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"topics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8084f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensions_df = df_sample.filter(regex=\".*tension$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7516bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cc6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensions_df.dropna(how=\"all\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c498ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56320af0",
   "metadata": {},
   "source": [
    "## Train stemmed_count vectorizer on 'full' dataset to get a complete vectorizer.\n",
    " This shouldn't be model leakage, however we'll need to find a way to mitigate having new words that the count_vectorizer hasn't seen yet.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec79d9c",
   "metadata": {},
   "source": [
    "### Due to small sizes of data with certain labels, we're only taking those with more than say 60 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b3f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_tension_list, tension_counts_results = process_annotations.get_tensions_with_enough_examples(\n",
    "    df, minimum_num_examples=60\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc8764",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_tension_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3244853",
   "metadata": {},
   "outputs": [],
   "source": [
    "tension_counts_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f282d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_tension_classifier = CountVectorizerTensionClassifier(accepted_tension_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba7bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usually takes around 6-7 min to train.\n",
    "cv_tension_classifier.train(df_full, df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0a5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_tension_classifier.analyse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7763c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_tension_classifier.persist_model(ARTIFACTS_BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8dba4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
